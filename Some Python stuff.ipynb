{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # This comment is from MSCA\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "pd.set_option('display.max_rows', 800)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "a = list(range(0,10))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a2bbdfb341f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "b = a + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "b = a * 2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a --> b\n",
      "0 --> 2\n",
      "1 --> 3\n",
      "2 --> 4\n",
      "3 --> 5\n",
      "4 --> 6\n",
      "5 --> 7\n",
      "6 --> 8\n",
      "7 --> 9\n",
      "8 --> 10\n",
      "9 --> 11\n"
     ]
    }
   ],
   "source": [
    "b = [x+2 for x in a]\n",
    "\n",
    "# Put print loop in function\n",
    "print(\"a --> b\")\n",
    "for x, y in zip(a, b):\n",
    "    print(x, \"-->\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mapping a lambda function - generally slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "b = list(map(lambda x: x+2, a))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to list comprehensions, but they return \"iterables\" as opposed to the full list. \n",
    "\n",
    "This saves memory because the new values are not created in memory, rather in run time as and when required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "b = [x+2 for x in a]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x000002B179493B48>\n"
     ]
    }
   ],
   "source": [
    "b_expr = (x+3 for x in a)\n",
    "print(b_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.extend(b_expr)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary of key-value pairs such that the \"Key\" is all the even numbers between 10-20 and the \"value\" is the cube of the corresponding key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 8, 4: 64, 6: 216, 8: 512}\n"
     ]
    }
   ],
   "source": [
    "d = dict({})\n",
    "\n",
    "for i in range(0,10,2):\n",
    "    d[i] = i**3\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 8, 4: 64, 6: 216, 8: 512}\n"
     ]
    }
   ],
   "source": [
    "d = {x:x**3 for x in range(0,10,2)}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 8, 4: 64, 6: 216, 8: 512}\n"
     ]
    }
   ],
   "source": [
    "d = {x:x**3 for x in range(0,10,1) if x%2 == 0}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested dictionary comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': {1.0}, 'second': {2.0}}\n"
     ]
    }
   ],
   "source": [
    "# nested_dict = {'first':{'a':1}, 'second':{'b':2}}\n",
    "# float_dict = {outer_k: {float(inner_v) for (inner_k, inner_v) in outer_v.items()} for (outer_k, outer_v) in nested_dict.items()}\n",
    "# print(float_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fibonacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fn = Fn-1 + Fn-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(num): \n",
    "    if num < 0: \n",
    "        print(\"Cannot be less than zero\") \n",
    "        return -1\n",
    "    elif num==1: \n",
    "        # First Fibonacci number is 0 \n",
    "        return 0\n",
    "    elif num==2: \n",
    "        # Second Fibonacci number is 1 \n",
    "        return 1\n",
    "    else: \n",
    "        return fibonacci(num-1) + fibonacci(num-2) \n",
    "    \n",
    "print(fibonacci(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions, classes and other objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtils:    \n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Constructor for the class\")\n",
    "        \n",
    "        \n",
    "    def read_csv(self, filepath, \n",
    "                 index_colname=None, \n",
    "                 nrows_to_read=None, skip_reading_rows=None):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath_or_buffer=filepath, \n",
    "                             index_col=index_colname, \n",
    "                             nrows=nrows_to_read, \n",
    "                             skiprows=skip_reading_rows)\n",
    "        except Exception as e:\n",
    "            print(\"Exception thrown while reading CSV file/buffer :\", e)\n",
    "            return pd.DataFrame({})\n",
    "        return df\n",
    "        \n",
    "        \n",
    "    def write_csv(self, filepath, \n",
    "                  df, write_index_col=True):\n",
    "        try:\n",
    "            df.to_csv(filepath, index=write_index_col)\n",
    "        except Exception as e:\n",
    "            print(\" Exception thrown while writing CSV file/buffer :\", e)\n",
    "            return -1\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    def save_obj_to_disk(self, obj, filename):\n",
    "        try:\n",
    "            with open(filename, 'wb') as handle:\n",
    "                pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def load_obj_from_disk(self, filename):\n",
    "        try:\n",
    "            with open(filename, 'rb') as handle:\n",
    "                b = pickle.load(handle)        \n",
    "                return b\n",
    "        except Exception as e:\n",
    "            print(e)    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameUtils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._labelencoders = None\n",
    "        self._onehotencoders = None\n",
    "        self._scalers = None\n",
    "        pass\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    # ENCODING UTILS\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def get_label_encoded(df, colname, inplace=True):\n",
    "        \"\"\"\n",
    "        Returns label encoded column appended to the data frame.\n",
    "        New column is pre-pended with \"le_\" followed by @colname\n",
    "        :param df: data frame\n",
    "        :param colname: name of the column to encode\n",
    "        :param inplace: if True, replaces the original columns instead of making new ones\n",
    "        :return: updated dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        # Sanity check\n",
    "        if colname not in df.columns:\n",
    "            raise ValueError(\"Column not in Dataframe!\")\n",
    "            return df\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[colname])\n",
    "        le_colname = colname\n",
    "        if not inplace:\n",
    "            le_colname = \"le_\" + le_colname\n",
    "        df[le_colname] = le.transform(df[colname])\n",
    "        return df, le\n",
    "\n",
    "\n",
    "    def labelencode_collist(df, collist, inplace=True):\n",
    "        \"\"\"\n",
    "        Returns label encoded columns appended to the data frame.\n",
    "        New columns are pre-pended with \"le_\" followed by @colname\n",
    "        :param df: data frame\n",
    "        :param collist: list with names of the columns to encode\n",
    "        :param inplace: if True, replaces the original columns instead of making new ones\n",
    "        :return: updated dataframe and dict of colname:encoder\n",
    "        \"\"\"\n",
    "\n",
    "        self._labelencoders= {}\n",
    "\n",
    "        for col in collist:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            df, le = get_label_encoded(df, col, inplace)\n",
    "    #         encoder_list[col] = le\n",
    "            self._labelencoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_onehot_encoded(df, colname, drop_original=True):\n",
    "        \"\"\"\n",
    "        Returns One Hot Encoded columns appended to the data frame.\n",
    "        New columns are pre-pended with @colname followed by encoded class label\n",
    "        :param df: data frame\n",
    "        :param colname: name of the column to encode\n",
    "        :param drop_original: if True, drops original column\n",
    "        :return: updated dataframe \n",
    "        \"\"\"\n",
    "\n",
    "        # Sanity check\n",
    "        if colname not in df.columns:\n",
    "            raise ValueError(\"Column not in Dataframe!\")\n",
    "            return data\n",
    "\n",
    "        ohe = OneHotEncoder(categorical_features=[0], handle_unknown=\"ignore\")\n",
    "        out = ohe.fit_transform(df[colname].values.reshape(-1,1)).toarray()\n",
    "        # Drop the first column - dummy variable trap\n",
    "        out = out[:,1:]\n",
    "        # Join with the original data frame\n",
    "        dfOneHot = pd.DataFrame(out, \n",
    "                                columns=[colname+\"_\"+str(int(i)) for i in range(out.shape[1])], \n",
    "                                index=df.index)\n",
    "        df = pd.concat([df, dfOneHot], axis=1)\n",
    "\n",
    "        if drop_original:\n",
    "            df.drop(colname, axis=1, inplace=True)\n",
    "\n",
    "        return df, ohe\n",
    "\n",
    "\n",
    "    def onehotencode_collist(df, collist, drop_original=True):\n",
    "        \"\"\"\n",
    "        Returns One Hot Encoded columns appended to the data frame.\n",
    "        New columns are pre-pended with @colname followed by encoded class label\n",
    "        :param df: data frame\n",
    "        :param collist: list with names of the columns to encode\n",
    "        :param drop_original: if True, drops original column\n",
    "        :return: updated dataframe and dict of colname:encoder\n",
    "        \"\"\"\n",
    "\n",
    "        self._onehotencoders= {}\n",
    "\n",
    "        for col in collist:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            print(col)\n",
    "            df, ohe = get_onehot_encoded(df, col, drop_original)\n",
    "            self._onehotencoders[col] = ohe\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "    # SCALING UTILS\n",
    "    # ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def scale_collist(df, collist):\n",
    "        \"\"\"\n",
    "        Returns One Hot Encoded columns appended to the data frame.\n",
    "        New columns are pre-pended with @colname followed by encoded class label\n",
    "        :param df: data frame\n",
    "        :param collist: list with names of the columns to encode\n",
    "        :param drop_original: if True, drops original column\n",
    "        :return: updated dataframe and dict of colname:encoder\n",
    "        \"\"\"\n",
    "\n",
    "        self._scalers = {}\n",
    "\n",
    "        for col in collist:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            df[col] = scaler.fit_transform(df[col].values.reshape(-1,1))\n",
    "            self._scalers[col] = scaler\n",
    "\n",
    "        return df, self._scalers\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
